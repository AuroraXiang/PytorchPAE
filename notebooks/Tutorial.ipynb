{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57627e3d-f9b1-4b56-b835-b207442b9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pae import AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85a4793-bb5e-4c4a-949f-73d44977f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c0269c-d6b5-4d72-835e-b9c5ab0cab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706abcb9-97ed-4051-a9e8-48cf2443833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9d1c51-9275-4e4e-880c-d07f72d4df51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3292840-0749-4ad1-a6cd-205ca784d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: add bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6128cc78-f5b0-429f-a30f-ad1ecdccd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of layers in networks\n",
    "n_layers     = 3\n",
    "\n",
    "## convolutional net specific parameters\n",
    "# number of channels in each layer for convolutional neural net\n",
    "out_channels = [16,16,16]\n",
    "# kernel sizes in each layer for conv net\n",
    "kernel_sizes = [4,3,2]\n",
    "# scaling factor in max pooling layer \n",
    "scale_facs   = [1,1,1] \n",
    "# padding values in each conv layer\n",
    "paddings     = [0,0,0]\n",
    "# stride values in each conv layer\n",
    "strides      = [2,1,1]\n",
    "# whether tp apply a layer normalization after conv layer\n",
    "layer_norm   = [True,True,True]\n",
    "# whether to train elemntwise affine parameters for normalization layer \n",
    "affine       = False\n",
    "\n",
    "## fully connected net specific parameters\n",
    "# output size of each fully connected layer\n",
    "out_sizes    = [256,128,64]\n",
    "\n",
    "## parameters that apply to both, fully connected and convolutional nets \n",
    "# dropout rate after each layer\n",
    "dropout_rate = [0.,0.,0.]\n",
    "# whether to Lipschitz regularize by bounding the spectral norm \n",
    "spec_norm    = True\n",
    "# activation function after each layer\n",
    "activations  = ['ReLU', 'ReLU','ReLU']\n",
    "# whether to add a bias in each layer or not\n",
    "bias         = [True, True, True]\n",
    "\n",
    "## general parameters\n",
    "# data dimensionality\n",
    "dim          = '2D'\n",
    "# latent space dimensionality\n",
    "latent_dim   = 8\n",
    "# number of channels in data\n",
    "input_c      = 1 \n",
    "# data dimensioality along one axis (only square data supported in 2D)\n",
    "input_dim    = 28\n",
    "# type of encoder and decoder network (either 'fc' or 'conv')\n",
    "encoder_type = 'conv'\n",
    "decoder_type = 'conv'\n",
    "\n",
    "# if True, the output is fed through a sigmoid layer to bring data values into range [0,1]\n",
    "final_sigmoid = True\n",
    "\n",
    "nepochs       = 20\n",
    "batchsize     = 64\n",
    "initial_lr    = 1e-2\n",
    "\n",
    "optimizer     = 'Adam'\n",
    "criterion     = 'MSELoss'\n",
    "\n",
    "scheduler     = 'ExponentialLR'\n",
    "scheduler_params = {'gamma':0.95}\n",
    "\n",
    "dataset       = 'MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861e682f-cde3-4571-91fa-658b8fb37952",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params      = {'input_c': input_c, 'input_dim': input_dim, 'latent_dim': latent_dim, 'encoder_type': encoder_type, 'decoder_type': decoder_type, 'dim': dim}\n",
    "conv_network_params = {'n_layers': n_layers, 'out_channels': out_channels, 'kernel_sizes': kernel_sizes, 'scale_facs': scale_facs, 'paddings': paddings,\\\n",
    "                       'strides': strides,'activations': activations, 'spec_norm': spec_norm, 'dropout_rate':dropout_rate, 'layer_norm': layer_norm,\\\n",
    "                       'affine': affine,'final_sigmoid': final_sigmoid}\n",
    "fc_network_params   = {'n_layers': n_layers, 'out_sizes': out_sizes,'activations': activations, 'spec_norm': spec_norm, 'dropout_rate':dropout_rate, \\\n",
    "                       'layer_norm': layer_norm, 'affine': affine, 'final_sigmoid': final_sigmoid}\n",
    "\n",
    "training_params     = {'batchsize': batchsize, 'initial_lr': initial_lr, 'optimizer': optimizer, 'criterion': criterion, \\\n",
    "                       'scheduler': scheduler, 'scheduler_params':scheduler_params}\n",
    "data_params         = {'dataset':dataset, 'loc': '/global/cscratch1/sd/vboehm/Datasets'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb34b69-8954-4984-b941-61d49252ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = AE.Autoencoder(general_params,data_params,conv_network_params, conv_network_params, training_params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "529cc63d-2a66-43bc-9762-e596e54b3a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 13, 13]             272\n",
      "         LayerNorm-2           [-1, 16, 13, 13]               0\n",
      "              ReLU-3           [-1, 16, 13, 13]               0\n",
      " AdaptiveMaxPool2d-4           [-1, 16, 13, 13]               0\n",
      "            Conv2d-5           [-1, 16, 11, 11]           2,320\n",
      "         LayerNorm-6           [-1, 16, 11, 11]               0\n",
      "              ReLU-7           [-1, 16, 11, 11]               0\n",
      " AdaptiveMaxPool2d-8           [-1, 16, 11, 11]               0\n",
      "            Conv2d-9           [-1, 16, 10, 10]           1,040\n",
      "        LayerNorm-10           [-1, 16, 10, 10]               0\n",
      "             ReLU-11           [-1, 16, 10, 10]               0\n",
      "AdaptiveMaxPool2d-12           [-1, 16, 10, 10]               0\n",
      "          Flatten-13                 [-1, 1600]               0\n",
      "           Linear-14                    [-1, 8]          12,808\n",
      "      ConvEncoder-15                    [-1, 8]               0\n",
      "          Flatten-16                    [-1, 8]               0\n",
      "           Linear-17                 [-1, 1600]          14,400\n",
      "          Reshape-18           [-1, 16, 10, 10]               0\n",
      "             ReLU-19           [-1, 16, 10, 10]               0\n",
      "         Upsample-20           [-1, 16, 10, 10]               0\n",
      "  ConvTranspose2d-21           [-1, 16, 11, 11]           1,040\n",
      "        LayerNorm-22           [-1, 16, 11, 11]               0\n",
      "             ReLU-23           [-1, 16, 11, 11]               0\n",
      "         Upsample-24           [-1, 16, 11, 11]               0\n",
      "  ConvTranspose2d-25           [-1, 16, 13, 13]           2,320\n",
      "        LayerNorm-26           [-1, 16, 13, 13]               0\n",
      "             ReLU-27           [-1, 16, 13, 13]               0\n",
      "         Upsample-28           [-1, 16, 13, 13]               0\n",
      "  ConvTranspose2d-29           [-1, 16, 28, 28]           4,112\n",
      "        LayerNorm-30           [-1, 16, 28, 28]               0\n",
      "  ConvTranspose2d-31            [-1, 1, 28, 28]              17\n",
      "          Sigmoid-32            [-1, 1, 28, 28]               0\n",
      "      ConvDecoder-33            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 38,329\n",
      "Trainable params: 38,329\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.60\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 0.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(AE, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f0ba1b-aaa9-4cb8-930e-ddbd06051ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, training loss: 3.0705e-02, validation loss: 2.2565e-02, learning rate: 9.5000e-03\n",
      "epoch: 1, training loss: 1.9731e-02, validation loss: 1.7925e-02, learning rate: 9.0250e-03\n",
      "epoch: 2, training loss: 1.8429e-02, validation loss: 1.8713e-02, learning rate: 8.5737e-03\n",
      "epoch: 3, training loss: 1.7735e-02, validation loss: 1.7695e-02, learning rate: 8.1451e-03\n",
      "epoch: 4, training loss: 1.7255e-02, validation loss: 1.6603e-02, learning rate: 7.7378e-03\n",
      "epoch: 5, training loss: 1.6942e-02, validation loss: 1.7432e-02, learning rate: 7.3509e-03\n",
      "epoch: 6, training loss: 1.6647e-02, validation loss: 1.6894e-02, learning rate: 6.9834e-03\n",
      "epoch: 7, training loss: 1.6478e-02, validation loss: 1.5405e-02, learning rate: 6.6342e-03\n",
      "epoch: 8, training loss: 1.6249e-02, validation loss: 1.6336e-02, learning rate: 6.3025e-03\n",
      "epoch: 9, training loss: 1.6109e-02, validation loss: 1.4930e-02, learning rate: 5.9874e-03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.03070538523015561,\n",
       "  0.019730683540370764,\n",
       "  0.018428563739679032,\n",
       "  0.017734579952670262,\n",
       "  0.017254996642255667,\n",
       "  0.016942056769598573,\n",
       "  0.01664743544245606,\n",
       "  0.016477843620312443,\n",
       "  0.016249115251823702,\n",
       "  0.016109050875738374],\n",
       " [tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward>),\n",
       "  tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward>)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, valid_loss = AE.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d78a0-bafa-4e11-82ca-a1b2ac3f9498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa02c24b-8d7d-4e2d-9017-fd2f00f1919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_pae.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17f80308-a1f0-4471-bc65-2ee9fdc068da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pytorch_pae.utils.output_shape(in_dim, stride, padding, kernel, dilation=1)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c999c6-b46f-41eb-8e78-d6be7bb8b773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
